{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#Deep Learning with Julia: MNIST Classification\n",
    "###############################################\n",
    "\n",
    "#Flux is a DL library for Julia that supports custom neural network modules as well as GPU\n",
    "\n",
    "\n",
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux.Optimise: Optimiser, WeightDecay\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy\n",
    "using Statistics, Random\n",
    "using Parameters: @with_kw\n",
    "using Logging: with_logger, global_logger\n",
    "using TensorBoardLogger: TBLogger, tb_overwrite, set_step!, set_step_increment!\n",
    "import ProgressMeter\n",
    "import MLDatasets\n",
    "import DrWatson: savename, struct2dict\n",
    "import BSON\n",
    "using CUDAapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_data (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A function for retrieving MNIST data built in to MLDatasets package\n",
    "function get_data(args)\n",
    "    xtrain, ytrain = MLDatasets.MNIST.traindata(Float32, dir=args.datapath)\n",
    "    xtest, ytest = MLDatasets.MNIST.testdata(Float32, dir=args.datapath)\n",
    "\n",
    "    xtrain = reshape(xtrain, 28, 28, 1, :)\n",
    "    xtest = reshape(xtest, 28, 28, 1, :)\n",
    "\n",
    "    ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)\n",
    "\n",
    "    train_loader = DataLoader(xtrain, ytrain, batchsize=args.batchsize, shuffle=true)\n",
    "    test_loader = DataLoader(xtest, ytest,  batchsize=args.batchsize)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5 (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic LeNet5 CNN Network for Classification\n",
    "function LeNet5(; imgsize=(28,28,1), nclasses=10) \n",
    "    out_conv_size = (imgsize[1]÷4 - 3, imgsize[2]÷4 - 3, 16)\n",
    "    \n",
    "    return Chain(\n",
    "            x -> reshape(x, imgsize..., :),\n",
    "            Conv((5, 5), imgsize[end]=>6, relu),\n",
    "            MaxPool((2, 2)),\n",
    "            Conv((5, 5), 6=>16, relu),\n",
    "            MaxPool((2, 2)),\n",
    "            x -> reshape(x, :, size(x, 4)),\n",
    "            Dense(prod(out_conv_size), 120, relu), \n",
    "            Dense(120, 84, relu), \n",
    "            Dense(84, nclasses)\n",
    "          )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_loss_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loss declaration and accuracy evaluation function\n",
    "#Special unicode symbols can be used directly in Julia to make the gap between math and programming smaller\n",
    "\n",
    "loss(ŷ, y) = logitcrossentropy(ŷ, y)\n",
    "\n",
    "function eval_loss_accuracy(loader, model, device)\n",
    "    l = 0f0\n",
    "    acc = 0\n",
    "    ntot = 0\n",
    "    for (x, y) in loader\n",
    "        x, y = x |> device, y |> device\n",
    "        ŷ = model(x)\n",
    "        l += loss(ŷ, y) * size(x)[end]        \n",
    "        acc += sum(onecold(ŷ |> cpu) .== onecold(y |> cpu))\n",
    "        ntot += size(x)[end]\n",
    "    end\n",
    "    return (loss = l/ntot |> round4, acc = acc/ntot*100 |> round4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "round4 (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params(model) = sum(length, Flux.params(model)) \n",
    "\n",
    "round4(x) = round(x, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Parameters package contains a @with_kw decorator for argument set declaration\n",
    "@with_kw mutable struct Args\n",
    "    η = 3e-4             # learning rate\n",
    "    λ = 0                # L2 regularizer param, implemented as weight decay\n",
    "    batchsize = 128      # batch size\n",
    "    epochs = 20          # number of epochs\n",
    "    seed = 0             # set seed > 0 for reproducibility\n",
    "    cuda = false         # if true use cuda (if available)\n",
    "    infotime = 1 \t     # report every `infotime` epochs\n",
    "    checktime = 5        # Save the model every `checktime` epochs. Set to 0 for no checkpoints.\n",
    "    tblogger = false      # log training with tensorboard\n",
    "    savepath = nothing    # results path. If nothing, construct a default path from Args. If existing, may overwrite\n",
    "    datapath = joinpath(\"home\",\"jberez\", \"Datasets\", \"MNIST\") # data path: change to your data directory \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Function\n",
    "function train(; kws...)\n",
    "    args = Args(; kws...)\n",
    "    args.seed > 0 && Random.seed!(args.seed)\n",
    "    use_cuda = args.cuda && CUDAapi.has_cuda_gpu()\n",
    "    if use_cuda\n",
    "        device = gpu\n",
    "        @info \"Training on GPU\"\n",
    "    else\n",
    "        device = cpu\n",
    "        @info \"Training on CPU\"\n",
    "    end\n",
    "\n",
    "    ## DATA\n",
    "    train_loader, test_loader = get_data(args)\n",
    "    @info \"Dataset MNIST: $(train_loader.nobs) train and $(test_loader.nobs) test examples\"\n",
    "\n",
    "    ## MODEL AND OPTIMIZER\n",
    "    model = LeNet5() |> device\n",
    "    @info \"LeNet5 model: $(num_params(model)) trainable params\"    \n",
    "    \n",
    "    ps = Flux.params(model)  \n",
    "\n",
    "    opt = ADAM(args.η) \n",
    "    if args.λ > 0 \n",
    "        opt = Optimiser(opt, WeightDecay(args.λ))\n",
    "    end\n",
    "    \n",
    "    ## LOGGING UTILITIES\n",
    "    if args.savepath == nothing\n",
    "        experiment_folder = savename(\"lenet\", args, scientific=4,\n",
    "                    accesses=[:batchsize, :η, :seed, :λ]) # construct path from these fields\n",
    "        args.savepath = joinpath(\"runs\", experiment_folder)\n",
    "    end\n",
    "    if args.tblogger \n",
    "        tblogger = TBLogger(args.savepath, tb_overwrite)\n",
    "        set_step_increment!(tblogger, 0) # 0 auto increment since we manually set_step!\n",
    "        @info \"TensorBoard logging at \\\"$(args.savepath)\\\"\"\n",
    "    end\n",
    "    \n",
    "    function report(epoch)\n",
    "        train = eval_loss_accuracy(train_loader, model, device)\n",
    "        test = eval_loss_accuracy(test_loader, model, device)        \n",
    "        println(\"Epoch: $epoch   Train: $(train)   Test: $(test)\")\n",
    "        if args.tblogger\n",
    "            set_step!(tblogger, epoch)\n",
    "            with_logger(tblogger) do\n",
    "                @info \"train\" loss=train.loss  acc=train.acc\n",
    "                @info \"test\"  loss=test.loss   acc=test.acc\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    ## TRAINING\n",
    "    @info \"Start Training\"\n",
    "    report(0)\n",
    "    for epoch in 1:args.epochs\n",
    "        p = ProgressMeter.Progress(length(train_loader))\n",
    "\n",
    "        for (x, y) in train_loader\n",
    "            x, y = x |> device, y |> device\n",
    "            gs = Flux.gradient(ps) do\n",
    "                ŷ = model(x)\n",
    "                loss(ŷ, y)\n",
    "            end\n",
    "            Flux.Optimise.update!(opt, ps, gs)\n",
    "            ProgressMeter.next!(p)   # comment out for no progress bar\n",
    "        end\n",
    "        \n",
    "        epoch % args.infotime == 0 && report(epoch)\n",
    "        if args.checktime > 0 && epoch % args.checktime == 0\n",
    "            !ispath(args.savepath) && mkpath(args.savepath)\n",
    "            modelpath = joinpath(args.savepath, \"model.bson\") \n",
    "            let model=cpu(model), args=struct2dict(args)\n",
    "                BSON.@save modelpath model epoch args\n",
    "            end\n",
    "            @info \"Model saved in \\\"$(modelpath)\\\"\"\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on CPU\n",
      "└ @ Main In[15]:11\n",
      "┌ Info: Dataset MNIST: 60000 train and 10000 test examples\n",
      "└ @ Main In[15]:16\n",
      "┌ Info: LeNet5 model: 44426 trainable params\n",
      "└ @ Main In[15]:20\n",
      "┌ Info: Start Training\n",
      "└ @ Main In[15]:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   Train: (loss = 2.3157f0, acc = 8.505)   Test: (loss = 2.3147f0, acc = 8.56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:51\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1   Train: (loss = 0.2013f0, acc = 93.9833)   Test: (loss = 0.1862f0, acc = 94.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2   Train: (loss = 0.1307f0, acc = 96.045)   Test: (loss = 0.1203f0, acc = 96.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3   Train: (loss = 0.1f0, acc = 96.935)   Test: (loss = 0.0915f0, acc = 97.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:29\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4   Train: (loss = 0.0801f0, acc = 97.5067)   Test: (loss = 0.0735f0, acc = 97.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:29\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5   Train: (loss = 0.0696f0, acc = 97.9083)   Test: (loss = 0.0648f0, acc = 97.79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/lenet_batchsize=128_seed=0_η=0.0003_λ=0/model.bson\"\n",
      "└ @ Main In[15]:77\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6   Train: (loss = 0.0621f0, acc = 98.0683)   Test: (loss = 0.0587f0, acc = 98.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7   Train: (loss = 0.0525f0, acc = 98.3567)   Test: (loss = 0.0549f0, acc = 98.27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8   Train: (loss = 0.0527f0, acc = 98.3583)   Test: (loss = 0.0535f0, acc = 98.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9   Train: (loss = 0.0452f0, acc = 98.5967)   Test: (loss = 0.0497f0, acc = 98.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10   Train: (loss = 0.044f0, acc = 98.675)   Test: (loss = 0.0504f0, acc = 98.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/lenet_batchsize=128_seed=0_η=0.0003_λ=0/model.bson\"\n",
      "└ @ Main In[15]:77\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11   Train: (loss = 0.0399f0, acc = 98.76)   Test: (loss = 0.0482f0, acc = 98.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:29\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12   Train: (loss = 0.0338f0, acc = 98.9683)   Test: (loss = 0.0402f0, acc = 98.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:27\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13   Train: (loss = 0.0302f0, acc = 99.0667)   Test: (loss = 0.0427f0, acc = 98.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14   Train: (loss = 0.029f0, acc = 99.1)   Test: (loss = 0.04f0, acc = 98.79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15   Train: (loss = 0.0307f0, acc = 98.99)   Test: (loss = 0.0437f0, acc = 98.67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/lenet_batchsize=128_seed=0_η=0.0003_λ=0/model.bson\"\n",
      "└ @ Main In[15]:77\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16   Train: (loss = 0.0291f0, acc = 99.0833)   Test: (loss = 0.0436f0, acc = 98.56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17   Train: (loss = 0.0221f0, acc = 99.335)   Test: (loss = 0.0382f0, acc = 98.69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18   Train: (loss = 0.0224f0, acc = 99.29)   Test: (loss = 0.0406f0, acc = 98.73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19   Train: (loss = 0.0188f0, acc = 99.4433)   Test: (loss = 0.037f0, acc = 98.83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:28\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20   Train: (loss = 0.02f0, acc = 99.3917)   Test: (loss = 0.0414f0, acc = 98.72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/lenet_batchsize=128_seed=0_η=0.0003_λ=0/model.bson\"\n",
      "└ @ Main In[15]:77\n"
     ]
    }
   ],
   "source": [
    "#Run the Training\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
