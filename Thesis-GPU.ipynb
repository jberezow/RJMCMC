{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "using Gen\n",
    "using PyPlot\n",
    "using CUDA\n",
    "#using Flux\n",
    "using Test\n",
    "using BenchmarkTools;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching maxthreads(::Type{CUDA.HostKernel})\nClosest candidates are:\n  maxthreads(!Matched::CUDA.HostKernel) at C:\\Users\\jbere\\.julia\\packages\\CUDA\\5t6R9\\src\\compiler\\execution.jl:264",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching maxthreads(::Type{CUDA.HostKernel})\nClosest candidates are:\n  maxthreads(!Matched::CUDA.HostKernel) at C:\\Users\\jbere\\.julia\\packages\\CUDA\\5t6R9\\src\\compiler\\execution.jl:264",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[36]:4"
     ]
    }
   ],
   "source": [
    "Threads.nthreads()\n",
    "has_cuda_gpu()\n",
    "CUDA.device()\n",
    "CUDA.maxthreads(CUDA.HostKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576-element Array{Float32,1}:\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " ⋮\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2^20\n",
    "x = fill(1.0f0, N)\n",
    "y = fill(2.0f0, N)\n",
    "\n",
    "y .+= x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test all(y .== 3.0f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sequential_add!(y, x)\n",
    "    for i in eachindex(y, x)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "fill!(y, 2)\n",
    "sequential_add!(y, x)\n",
    "@test all(y .== 3.0f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function parallel_add!(y, x)\n",
    "    Threads.@threads for i in eachindex(y, x)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "fill!(y, 2)\n",
    "parallel_add!(y, x)\n",
    "@test all(y .== 3.0f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  253.199 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime sequential_add!($y, $x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  177.000 μs (23 allocations: 3.34 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime parallel_add!($y, $x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `Target(triple::String)` is deprecated, use `Target(; triple = triple)` instead.\n",
      "│   caller = ip:0x0\n",
      "└ @ Core :-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPUS\n",
    "x_d = CUDA.fill(1.0f0, N)  # a vector stored on the GPU filled with 1.0 (Float32)\n",
    "y_d = CUDA.fill(2.0f0, N)  # a vector stored on the GPU filled with 2.0\n",
    "y_d .+= x_d\n",
    "@test all(Array(y_d) .== 3.0f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  197.200 μs (69 allocations: 1.88 KiB)\n"
     ]
    }
   ],
   "source": [
    "function add_broadcast!(y, x)\n",
    "    CUDA.@sync y .+= x\n",
    "    return\n",
    "end\n",
    "\n",
    "@btime add_broadcast!($y_d, $x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gpu_add1!(y, x)\n",
    "    for i = 1:length(y)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "fill!(y_d, 2)\n",
    "@cuda gpu_add1!(y_d, x_d)\n",
    "@test all(Array(y_d) .== 3.0f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  146.722 ms (47 allocations: 1.23 KiB)\n"
     ]
    }
   ],
   "source": [
    "function bench_gpu1!(y, x)\n",
    "    CUDA.@sync begin\n",
    "        @cuda gpu_add1!(y, x)\n",
    "    end\n",
    "end\n",
    "\n",
    "@btime bench_gpu1!($y_d, $x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gpu_add2!(y, x)\n",
    "    index = threadIdx().x    # this example only requires linear indexing, so just use `x`\n",
    "    stride = blockDim().x\n",
    "    for i = index:stride:length(y)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "fill!(y_d, 2)\n",
    "@cuda threads=256 gpu_add2!(y_d, x_d)\n",
    "@test all(Array(y_d) .== 3.0f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.322 ms (47 allocations: 1.23 KiB)\n"
     ]
    }
   ],
   "source": [
    "function bench_gpu2!(y, x)\n",
    "    CUDA.@sync begin\n",
    "        @cuda threads=256 gpu_add2!(y, x)\n",
    "    end\n",
    "end\n",
    "\n",
    "@btime bench_gpu2!($y_d, $x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  177.900 μs (52 allocations: 1.31 KiB)\n"
     ]
    }
   ],
   "source": [
    "function gpu_add3!(y, x)\n",
    "    index = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    stride = blockDim().x * gridDim().x\n",
    "    for i = index:stride:length(y)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "numblocks = ceil(Int, N/256)\n",
    "\n",
    "fill!(y_d, 2)\n",
    "@cuda threads=256 blocks=numblocks gpu_add3!(y_d, x_d)\n",
    "@test all(Array(y_d) .== 3.0f0)\n",
    "\n",
    "function bench_gpu3!(y, x)\n",
    "    numblocks = ceil(Int, length(y)/256)\n",
    "    CUDA.@sync begin\n",
    "        @cuda threads=256 blocks=numblocks gpu_add3!(y, x)\n",
    "    end\n",
    "end\n",
    "\n",
    "@btime bench_gpu3!($y_d, $x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1, block 16\r\n",
      "thread 2, block 16\r\n",
      "thread 3, block 16\r\n",
      "thread 4, block 16\r\n",
      "thread 5, block 16\r\n",
      "thread 6, block 16\r\n",
      "thread 7, block 16\r\n",
      "thread 8, block 16\r\n",
      "thread 9, block 16\r\n",
      "thread 10, block 16\r\n",
      "thread 11, block 16\r\n",
      "thread 12, block 16\r\n",
      "thread 13, block 16\r\n",
      "thread 14, block 16\r\n",
      "thread 15, block 16\r\n",
      "thread 16, block 16\r\n"
     ]
    }
   ],
   "source": [
    "function gpu_add2_print!(y, x)\n",
    "    index = threadIdx().x    # this example only requires linear indexing, so just use `x`\n",
    "    stride = blockDim().x\n",
    "    @cuprintln(\"thread $index, block $stride\")\n",
    "    for i = index:stride:length(y)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "@cuda threads=16 gpu_add2_print!(y_d, x_d)\n",
    "synchronize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
