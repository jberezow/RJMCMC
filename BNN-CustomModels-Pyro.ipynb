{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Predictive' from 'pyro.infer' (/home/jberez/anaconda3/lib/python3.7/site-packages/pyro/infer/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fb99619b545b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mListedColormap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPredictive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_enumerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyroModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyroParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyroSample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_pyro_module_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMCMC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Predictive' from 'pyro.infer' (/home/jberez/anaconda3/lib/python3.7/site-packages/pyro/infer/__init__.py)"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "#Experimenting with Bayesian Models in Pyro\n",
    "#------------------------------------------\n",
    "# 1. Using a simple Bayes NN to fit a basic curve\n",
    "# 2. Using a simple Bayes NN for a classification task\n",
    "# 3. Adding a discrete hyper-parameter for number of output nodes in a Bayes NN\n",
    "\n",
    "#Library Calls\n",
    "import torch\n",
    "import pyro\n",
    "import matplotlib\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from torch import nn\n",
    "from matplotlib.colors import ListedColormap\n",
    "from pyro.distributions import Normal, Categorical\n",
    "from pyro.infer import Predictive, config_enumerate\n",
    "from pyro.nn.module import PyroModule, PyroParam, PyroSample, to_pyro_module_\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from pyro.infer.mcmc import HMC\n",
    "from pyro.infer import EmpiricalMarginal\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro import poutine\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sample Data for Curve Fitting\n",
    "\n",
    "#Curve 1. Sin Wave\n",
    "x = np.array([np.linspace(-20, 20, 1000)])\n",
    "eps = np.random.randn(1000) #* 0.15*(x**2)\n",
    "y = (20*np.sin(0.2*x)) + eps\n",
    "\n",
    "#Curve 2. Basic Noisy Curve\n",
    "#x = np.array([[-4, -3, -2, -1, 0, 1, 2, 3, 4, 5]])\n",
    "#y = np.array([[1.0, 1.3, 1.4, 1.1, 0.6, -0.2, -0.8, -0.6, 0.3, 0.8]])\n",
    "\n",
    "#Curve 3. Noisy Linear Function\n",
    "#x = np.array([[-4, -3, -2, -1, 0, 1, 2, 3, 4, 5]])\n",
    "#y = 3 * x + 2\n",
    "#z = torch.normal(0,2,(10,1))\n",
    "#x = 3 * x + 2 + z\n",
    "\n",
    "#Plot Sample Data\n",
    "#plt.scatter(x, y)\n",
    "x = torch.t(torch.tensor(x).float())\n",
    "y = torch.t(torch.tensor(y).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Deep Vanilla FNN (No Bayesian)\n",
    "class BNN(torch.nn.Module):\n",
    "    def __init__(self, n_hidden=32, n_out=1):\n",
    "        super(BNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, n_hidden)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(n_hidden, n_out)\n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = self.tanh1(output)\n",
    "        output = self.fc2(output)\n",
    "        return output\n",
    "\n",
    "bayes_net = BNN()\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(bayes_net.parameters(), lr=0.05)\n",
    "\n",
    "for i in range(1000):\n",
    "    optim.zero_grad()\n",
    "    predictions = bayes_net(x)\n",
    "    loss = loss_function(predictions, y)\n",
    "    loss.backward()\n",
    "    if i%100 == 0:\n",
    "        xx = torch.t(torch.tensor(np.array([np.linspace(-20, 20, 1000)])).float())\n",
    "        yy = bayes_net.forward(xx).detach().numpy()\n",
    "        plt.scatter(xx, yy)\n",
    "        #plt.scatter(x, predictions.detach().numpy())\n",
    "    optim.step()\n",
    "\n",
    "xx = torch.t(torch.tensor(np.array([np.linspace(-20, 20, 1000)])).float())\n",
    "yy = bayes_net.forward(xx).detach().numpy()\n",
    "\n",
    "plt.scatter(xx, yy)\n",
    "plt.scatter(x,y)\n",
    "plt.scatter(x, predictions.detach().numpy(), c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bayesian NN 1: Curve Fitting\n",
    "class BNN(nn.Module):\n",
    "    def __init__(self, n_hidden=32, n_out=1):\n",
    "        super(BNN, self).__init__()\n",
    "        self.linear = nn.Linear(1, n_hidden)\n",
    "        self.tanh1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.tanh2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(n_hidden, n_out)\n",
    "        self.sig = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        output = self.linear(x)\n",
    "        output = self.tanh1(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.tanh2(output)\n",
    "        output = self.linear3(output)\n",
    "\n",
    "        with pyro.plate('data', x.shape[0]):\n",
    "            #self.sig2 = pyro.sample('sig2',dist.HalfNormal(self.sig).expand([1]).to_event(1))\n",
    "            obs = pyro.sample(\"obs\",dist.Normal(output,self.sig),obs=y)\n",
    "        return obs\n",
    "\n",
    "net = BNN()\n",
    "to_pyro_module_(net)\n",
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "def guide(x,y):\n",
    "    # First layer weight distribution priors\n",
    "    l1_mu = torch.randn_like(net.linear.weight)\n",
    "    l1_sig = torch.randn_like(net.linear.weight)\n",
    "    l1_mu_p = pyro.param(\"l1_mu\", l1_mu)\n",
    "    l1_sig_p = softplus(pyro.param(\"l1_sig\", l1_sig))\n",
    "    l1w_prior = Normal(loc=l1_mu_p, scale=l1_sig_p)\n",
    "    # First layer bias distribution priors\n",
    "    l1b_mu = torch.randn_like(net.linear.bias)\n",
    "    l1b_sig = torch.randn_like(net.linear.bias)\n",
    "    l1b_mu_p = pyro.param(\"l1b_mu\", l1b_mu)\n",
    "    l1b_sig_p = softplus(pyro.param(\"l1b_sig\", l1b_sig))\n",
    "    l1b_prior = Normal(loc=l1b_mu_p, scale=l1b_sig_p)\n",
    "    # Output layer weight distribution priors\n",
    "    l2_mu = torch.randn_like(net.linear.weight)\n",
    "    l2_sig = torch.randn_like(net.linear.weight)\n",
    "    l2_mu_p = pyro.param(\"l2_mu\", l2_mu)\n",
    "    l2_sig_p = softplus(pyro.param(\"l2_sig\", l2_sig))\n",
    "    l2w_prior = Normal(loc=l2_mu_p, scale=l2_sig_p)\n",
    "    # Output layer bias distribution priors\n",
    "    l2b_mu = torch.randn_like(net.linear.bias)\n",
    "    l2b_sig = torch.randn_like(net.linear.bias)\n",
    "    l2b_mu_p = pyro.param(\"l2b_mu\", l2b_mu)\n",
    "    l2b_sig_p = softplus(pyro.param(\"l2b_sig\", l2b_sig))\n",
    "    l2b_prior = Normal(loc=l2b_mu_p, scale=l2b_sig_p)\n",
    "    # Output layer weight distribution priors\n",
    "    l3_mu = torch.randn_like(net.linear3.weight)\n",
    "    l3_sig = torch.randn_like(net.linear3.weight)\n",
    "    l3_mu_p = pyro.param(\"l3_mu\", l2_mu)\n",
    "    l3_sig_p = softplus(pyro.param(\"l3_sig\", l3_sig))\n",
    "    l3w_prior = Normal(loc=l3_mu_p, scale=l3_sig_p)\n",
    "    # Output layer bias distribution priors\n",
    "    l3b_mu = torch.randn_like(net.linear3.bias)\n",
    "    l3b_sig = torch.randn_like(net.linear3.bias)\n",
    "    l3b_mu_p = pyro.param(\"l3b_mu\", l3b_mu)\n",
    "    l3b_sig_p = softplus(pyro.param(\"l3b_sig\", l3b_sig))\n",
    "    l3b_prior = Normal(loc=l3b_mu_p, scale=l3b_sig_p)\n",
    "\n",
    "    sig_prior = dist.HalfNormal(10)\n",
    "\n",
    "    priors = {'linear.weight': l1w_prior, 'linear.bias': l1b_prior, 'linear2.weight': l2w_prior, 'linear2.bias': l2b_prior, 'linear3.weight': l3w_prior, 'linear3.bias': l3b_prior, 'sig': sig_prior}\n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "    \n",
    "    return lifted_module()\n",
    "\n",
    "adam = pyro.optim.Adam({\"lr\": 0.05})\n",
    "\n",
    "svi = pyro.infer.SVI(net, guide, adam, loss=pyro.infer.Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MCMC Training Attempt\n",
    "pyro.infer.mcmc.util.initialize_model(net, (x, y))\n",
    "hmc_kernel = HMC(net, step_size=0.08, num_steps=4)\n",
    "mcmc = MCMC(hmc_kernel, num_samples=1000, warmup_steps=100)\n",
    "mcmc.run(x, y)\n",
    "samples = mcmc.get_samples()\n",
    "samples2 = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = pyro.infer.predictive.Predictive(net, samples, num_samples=2)\n",
    "model2 = pyro.infer.predictive.Predictive(net, samples2, num_samples=1)\n",
    "z = model(xx)['obs'][0,:,0].detach().numpy()\n",
    "z2 = model2(xx)['obs'][0,:,0].detach().numpy()\n",
    "plt.scatter(xx, z)\n",
    "plt.scatter(xx, z2)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyro.infer.predictive.Predictive(net, samples, num_samples=2)\n",
    "model2 = pyro.infer.predictive.Predictive(net, samples2, num_samples=1)\n",
    "z = model(x)['obs'][0,:,0].detach().numpy()\n",
    "z2 = model(x)['obs'][0,:,1].detach().numpy()\n",
    "plt.scatter(x, z)\n",
    "plt.scatter(x, z2)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "pyro.clear_param_store()\n",
    "num_iterations = 30000\n",
    "losses = []\n",
    "for j in range(num_iterations):\n",
    "    #Calculate Loss, take a Gradient Step\n",
    "    loss = svi.step(x, y)\n",
    "    losses.append(loss/len(x))\n",
    "    if j % 50 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x)))\n",
    "        print(net.sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = 1\n",
    "def predict(x):\n",
    "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
    "    yhats = [bayes_net(x) for model in sampled_models]\n",
    "    mean = torch.mean(torch.stack(yhats), 0)\n",
    "    return mean#, torch.stack(yhats)[:,:,0]\n",
    "\n",
    "#z, zs = predict(x)\n",
    "#print(zs)\n",
    "\n",
    "#print(zs.size())\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "for i in range(5):\n",
    "    xx = torch.t(torch.tensor(np.array([np.linspace(-50, 50, 1000)])).float())\n",
    "    zz = predict(xx).detach().numpy()\n",
    "    z = predict(x).detach().numpy()\n",
    "    plt.scatter(xx, zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80])\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#Task 2 - Classification\n",
    "#########################\n",
    "\n",
    "#Set up Gaussian Data\n",
    "num_samples = 20\n",
    "mu1, mu2, mu3, mu4 = [[0.5,0.5], [0.5,2.0], [2.0,0.5], [2.0,2.0]]\n",
    "sd = np.array([[0.15, 0.0], [0.0, 0.15]])\n",
    "x1 = np.random.multivariate_normal(mu1, sd, (10))\n",
    "x2 = np.random.multivariate_normal(mu2, sd, (num_samples))\n",
    "x3 = np.random.multivariate_normal(mu3, sd, (10))\n",
    "x4 = np.random.multivariate_normal(mu4, sd, (num_samples))\n",
    "x5 = np.random.multivariate_normal([0.5,3.5], sd, (10))\n",
    "x6 = np.random.multivariate_normal([3.0,2.5], sd, (10))\n",
    "x3 = np.concatenate((x3,x5))\n",
    "x1 = np.concatenate((x1,x6))\n",
    "\n",
    "#plt.scatter(x1[:,0],x1[:,1], c='green')\n",
    "#plt.scatter(x2[:,0],x2[:,1], c='blue')\n",
    "#plt.scatter(x3[:,0],x3[:,1], c='blue')\n",
    "#plt.scatter(x4[:,0],x4[:,1], c='purple')\n",
    "\n",
    "#Create Labels\n",
    "y = np.array([int(np.floor(i/num_samples)) for i in range(num_samples*4)])\n",
    "#y[100:300] = 2\n",
    "y[0:20] = 0\n",
    "y[20:40] = 1\n",
    "y[40:] = 2\n",
    "\n",
    "x = np.concatenate((x1,x2,x3,x4))\n",
    "newcmp = ListedColormap(['green','red','blue','purple'])\n",
    "#plt.scatter(x[:,0],x[:,1],c=y,cmap=newcmp)\n",
    "\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[2, 3], [4,5]])\n",
    "print(min(test[1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 101/101 [00:04, 20.23it/s, step size=6.25e-02, acc. prob=0.007]\n"
     ]
    }
   ],
   "source": [
    "choices = []\n",
    "p_mus = []\n",
    "def count_it(branch):\n",
    "    if branch == 0:\n",
    "        choices.append(0)\n",
    "    else:\n",
    "        choices.append(1)\n",
    "def p_it(branch):\n",
    "    p_mus.append(branch)\n",
    "\n",
    "class BNN2(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=32, output_size=4):\n",
    "        super(BNN2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, 3)\n",
    "        self.out2 = nn.Linear(hidden_size, 4)\n",
    "        #self.p = nn.Parameter(torch.rand(1))\n",
    "        self.p_mu = nn.Parameter(torch.rand(100))\n",
    "        self.p_sd = nn.Parameter(torch.rand(1))\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        output = self.fc1(x)\n",
    "        output = nn.functional.relu(output)\n",
    "        output1 = self.out(output)\n",
    "        output2 = self.out2(output)\n",
    "        new_column = torch.zeros_like(output1[:,0:1])\n",
    "        #output1 = torch.cat((output1,new_column),dim=1)\n",
    "        #output = output1\n",
    "\n",
    "        #z = pyro.sample('z',dist.Normal(0,1))\n",
    "        #p = self.p_mu + self.p_sd * z\n",
    "        #p_it(p.item())\n",
    "\n",
    "        #output = p*(output1) + (1-p)*(output2)\n",
    "        \n",
    "        #if p.item() <= 0.5:\n",
    "            #count_it(0)\n",
    "            #new_column = torch.zeros_like(output1[:,0:1])\n",
    "            #output1 = torch.cat((output1,new_column),dim=1)\n",
    "            #output = output1\n",
    "        #elif p.item() > 0.5:\n",
    "            #count_it(1)\n",
    "            #output = output2\n",
    "        \n",
    "        #lhat = nn.functional.softmax(output1,dim=1)\n",
    "        #lhat = torch.cat((lhat,new_column),dim=1)\n",
    "        lhat = nn.functional.softmax(output2,dim=1)\n",
    "\n",
    "        #score1 = (sum(sum(torch.abs(lhat - torch.tensor([0.25, 0.25, 0.5, 0])))))\n",
    "        #score2 = (sum(sum(torch.abs(lhat2 - torch.tensor([0.25, 0.25, 0.5, 0])))))\n",
    "        #pt = 1 - (score1 / (score1 + score2))\n",
    "        #if pt > np.random.rand():\n",
    "            #lhat = lhat\n",
    "            #count_it(1)\n",
    "        #else:\n",
    "            #lhat = lhat2\n",
    "            #count_it(0)\n",
    "\n",
    "        return lhat\n",
    "\n",
    "net = BNN2()\n",
    "to_pyro_module_(net)\n",
    "def model(x, y):\n",
    "    p_mu_prior = dist.Normal(0.5, 1.0)\n",
    "    p_sd_prior = dist.HalfNormal(0.1)\n",
    "    fc1w_prior = Normal(loc=torch.zeros_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight)*3)\n",
    "    fc1b_prior = Normal(loc=torch.zeros_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias)*3)\n",
    "    outw_prior = Normal(loc=torch.zeros_like(net.out.weight), scale=torch.ones_like(net.out.weight)*3)\n",
    "    outb_prior = Normal(loc=torch.zeros_like(net.out.bias), scale=torch.ones_like(net.out.bias)*3)\n",
    "    out2w_prior = Normal(loc=torch.zeros_like(net.out2.weight), scale=torch.ones_like(net.out2.weight)*3)\n",
    "    out2b_prior = Normal(loc=torch.zeros_like(net.out2.bias), scale=torch.ones_like(net.out2.bias)*3)\n",
    "    #in_k = pyro.sample('k',Categorical(probs=torch.tensor([net.p,1-net.p])))\n",
    "    priors = {'p_mu': p_mu_prior, 'p_sd': p_sd_prior, 'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,  'out.weight': outw_prior, 'out.bias': outb_prior, 'out2.weight': out2w_prior, 'out2.bias': out2b_prior}\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    #p = pyro.sample(\"p\", dist.Beta(2,2))\n",
    "\n",
    "    lhat = lifted_reg_model(x)\n",
    "    #Decide which network vector to use\n",
    "    #score1 = (sum(sum(torch.abs(t1 - torch.tensor([0.25, 0.25, 0.5, 0])))))\n",
    "    #score2 = (sum(sum(torch.abs(t2 - torch.tensor([0.25, 0.25, 0.5, 0])))))\n",
    "    #pt = 1 - (score1 / (score1 + score2))\n",
    "    #prop = np.random.rand()\n",
    "    \n",
    "    #if pt >= prop:\n",
    "        #count_it(1)\n",
    "        #lhat = t1\n",
    "    #else:\n",
    "        #count_it(0)\n",
    "        #lhat = t2\n",
    "    \n",
    "    with pyro.plate('data', x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", Categorical(probs=lhat), obs=y)\n",
    "\n",
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "nuts_kernel = pyro.infer.mcmc.NUTS(model)    \n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(x,y)\n",
    "\n",
    "def guide(x, y):\n",
    "\n",
    "    #p variable for model selection\n",
    "    a = torch.tensor([1.0]).float()\n",
    "    b = torch.tensor([0.1]).float()\n",
    "    alpha = pyro.param(\"alpha\", a)\n",
    "    beta = pyro.param(\"beta\", b)\n",
    "    #model_indicator_prior = dist.Beta(alpha, beta)\n",
    "    p_mu_prior = dist.Normal(0.5, alpha)\n",
    "    p_sd_prior = dist.HalfNormal(beta)\n",
    "\n",
    "    # First layer weight distribution priors\n",
    "    fc1w_mu = torch.randn_like(net.fc1.weight)\n",
    "    fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
    "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
    "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
    "    fc1w_prior = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param)\n",
    "    # First layer bias distribution priors\n",
    "    fc1b_mu = torch.randn_like(net.fc1.bias)\n",
    "    fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
    "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
    "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
    "    fc1b_prior = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
    "    # Output layer weight distribution priors\n",
    "    outw_mu = torch.randn_like(net.out.weight)\n",
    "    outw_sigma = torch.randn_like(net.out.weight)\n",
    "    outw_mu_param = pyro.param(\"outw_mu\", outw_mu)\n",
    "    outw_sigma_param = softplus(pyro.param(\"outw_sigma\", outw_sigma))\n",
    "    outw_prior = Normal(loc=outw_mu_param, scale=outw_sigma_param).independent(1)\n",
    "    # Output layer bias distribution priors\n",
    "    outb_mu = torch.randn_like(net.out.bias)\n",
    "    outb_sigma = torch.randn_like(net.out.bias)\n",
    "    outb_mu_param = pyro.param(\"outb_mu\", outb_mu)\n",
    "    outb_sigma_param = softplus(pyro.param(\"outb_sigma\", outb_sigma))\n",
    "    outb_prior = Normal(loc=outb_mu_param, scale=outb_sigma_param)\n",
    "    # Output layer 2 weight distribution priors\n",
    "    out2w_mu = torch.randn_like(net.out2.weight)\n",
    "    out2w_sigma = torch.randn_like(net.out2.weight)\n",
    "    out2w_mu_param = pyro.param(\"out2w_mu\", out2w_mu)\n",
    "    out2w_sigma_param = softplus(pyro.param(\"out2w_sigma\", out2w_sigma))\n",
    "    out2w_prior = Normal(loc=out2w_mu_param, scale=out2w_sigma_param).independent(1)\n",
    "    # Output layer 2 bias distribution priors\n",
    "    out2b_mu = torch.randn_like(net.out2.bias)\n",
    "    out2b_sigma = torch.randn_like(net.out2.bias)\n",
    "    out2b_mu_param = pyro.param(\"out2b_mu\", out2b_mu)\n",
    "    out2b_sigma_param = softplus(pyro.param(\"out2b_sigma\", out2b_sigma))\n",
    "    out2b_prior = Normal(loc=out2b_mu_param, scale=out2b_sigma_param)\n",
    "\n",
    "    priors = {'p_mu': p_mu_prior, 'p_sd': p_sd_prior, 'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior, 'out.weight': outw_prior, 'out.bias': outb_prior, 'out2.weight': out2w_prior, 'out2.bias': out2b_prior}\n",
    "    \n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "    \n",
    "    return lifted_module()\n",
    "\n",
    "optim = pyro.optim.Adam({\"lr\": 0.005})\n",
    "svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "pyro.clear_param_store()\n",
    "num_iterations = 2001\n",
    "ims = []\n",
    "for j in range(num_iterations):\n",
    "    #Calculate Loss, take a Gradient Step\n",
    "    loss = svi.step(x, y)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x)))\n",
    "        #print(np.mean(choices))\n",
    "        \n",
    "        def predict(x):\n",
    "            sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
    "            yhats = [f(x).data for f in sampled_models]\n",
    "            mean = torch.mean(torch.stack(yhats), 0)\n",
    "            return np.argmax(mean.numpy(), axis=1), mean\n",
    "        \n",
    "        #im = plot_it()\n",
    "        #ims.append(im)\n",
    "#kwargs_write = {'fps':15.0, 'quantizer':'nq'}\n",
    "#imageio.mimsave('./training.gif', ims, fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = 1\n",
    "def predict(x):\n",
    "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
    "    yhats = [f(x).data for f in sampled_models]\n",
    "    mean = torch.mean(torch.stack(yhats), 0)\n",
    "    return np.argmax(mean.numpy(), axis=1), mean\n",
    "\n",
    "z, z_vals = predict(x)\n",
    "\n",
    "xx = torch.tensor(np.linspace(-1.5, 5, 100))\n",
    "gridx, gridy = torch.meshgrid(xx, xx)\n",
    "gridx = torch.flatten(gridx)\n",
    "gridy = torch.flatten(gridy)\n",
    "gridz = torch.t(torch.stack((gridx,gridy)).float())\n",
    "\n",
    "z2, z2_vals = predict(gridz)\n",
    "from matplotlib.colors import ListedColormap\n",
    "newcmp = ListedColormap(['green','red','blue','purple'])\n",
    "#plt.scatter(gridz[:,0],gridz[:,1],alpha=0.05,c=z2,cmap=newcmp)\n",
    "#plt.scatter(x[:,0],x[:,1],c=y,cmap=newcmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greenMap = plt.cm.Greens\n",
    "redMap = plt.cm.Reds\n",
    "blueMap = plt.cm.Blues\n",
    "purpleMap = plt.cm.Purples\n",
    "\n",
    "grmap = greenMap(np.arange(greenMap.N))\n",
    "rdmap = redMap(np.arange(redMap.N))\n",
    "blmap = blueMap(np.arange(blueMap.N))\n",
    "prmap = purpleMap(np.arange(purpleMap.N))\n",
    "\n",
    "grmap[:,-1] = np.linspace(0, 1, greenMap.N)**10\n",
    "rdmap[:,-1] = np.linspace(0, 1, redMap.N)**10\n",
    "blmap[:,-1] = np.linspace(0, 1, blueMap.N)**10\n",
    "prmap[:,-1] = np.linspace(0, 1, purpleMap.N)**10\n",
    "\n",
    "grmap[:100,-1] = 0\n",
    "rdmap[:100,-1] = 0\n",
    "blmap[:100,-1] = 0\n",
    "prmap[:100,-1] = 0\n",
    "\n",
    "grmap = ListedColormap(grmap)\n",
    "rdmap = ListedColormap(rdmap)\n",
    "blmap = ListedColormap(blmap)\n",
    "prmap = ListedColormap(prmap)\n",
    "\n",
    "newcmp2 = ListedColormap(['green','red','blue'])\n",
    "\n",
    "def plot_it():    \n",
    "    #z, z_vals = predict(x)\n",
    "\n",
    "    xx = torch.tensor(np.linspace(-1.5, 4, 100))\n",
    "    yy = torch.tensor(np.linspace(-1.5, 5, 100))\n",
    "    gridx, gridy = torch.meshgrid(xx, yy)\n",
    "    gridx = torch.flatten(gridx)\n",
    "    gridy = torch.flatten(gridy)\n",
    "    gridz = torch.t(torch.stack((gridx,gridy)).float())\n",
    "\n",
    "    z2, z2_vals = predict(gridz)\n",
    "\n",
    "    #sdevs = torch.std(z2_vals, axis=1)\n",
    "    green = z2_vals[:,0]\n",
    "    red = z2_vals[:,1]\n",
    "    blue = z2_vals[:,2]\n",
    "    purple = z2_vals[:,3]\n",
    "\n",
    "    green_grid = z2_vals[:,0].reshape(100,100)\n",
    "    red_grid = z2_vals[:,1].reshape(100,100)\n",
    "    blue_grid = z2_vals[:,2].reshape(100,100)\n",
    "    purple_grid = z2_vals[:,3].reshape(100,100)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.scatter(gridz[:,0],gridz[:,1],c=green, cmap=grmap)\n",
    "    ax.scatter(gridz[:,0],gridz[:,1],c=red, cmap=rdmap)\n",
    "    ax.scatter(gridz[:,0],gridz[:,1],c=blue, cmap=blmap)\n",
    "    ax.scatter(gridz[:,0],gridz[:,1],c=purple, cmap=prmap)\n",
    "    #ax.scatter(gridz[:,0],gridz[:,1],c=sdevs, cmap='Greys')\n",
    "    ax.scatter(x[:,0],x[:,1],c=y,cmap=newcmp2)\n",
    "\n",
    "    #fig = plt.figure(frameon=False)\n",
    "\n",
    "    #z1 = plt.imshow(green_grid, cmap=grmap, origin='lower', interpolation = 'bilinear')\n",
    "    #z2 = plt.imshow(red_grid, cmap=rdmap, origin='lower', interpolation = 'bilinear', alpha=0.8)\n",
    "    #z3 = plt.imshow(blue_grid, cmap=blmap, origin='lower', interpolation = 'bilinear', alpha=0.7)\n",
    "    #z4 = plt.imshow(purple_grid, cmap=prmap, origin='lower', interpolation = 'bilinear', alpha=0.5)\n",
    "\n",
    "    #Save a GIF\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test2 = plot_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs_write = {'fps':15.0, 'quantizer':'nq'}\n",
    "imageio.mimsave('./training2.gif', ims, fps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "xx = torch.tensor(np.linspace(-20, 120, 100))\n",
    "yy = torch.tensor(np.linspace(-20, 120, 100))\n",
    "gridx, gridy = torch.meshgrid(xx, yy)\n",
    "gridx = torch.flatten(gridx)\n",
    "gridy = torch.flatten(gridy)\n",
    "gridz = torch.t(torch.stack((gridx,gridy)).float())\n",
    "\n",
    "z2, z2_vals = predict(gridz)\n",
    "\n",
    "sdevs = torch.std(z2_vals, axis=0)\n",
    "green = z2_vals[:,0]\n",
    "red = z2_vals[:,1]\n",
    "blue = z2_vals[:,2]\n",
    "purple = z2_vals[:,3]\n",
    "\n",
    "greenMap = plt.cm.Greens\n",
    "redMap = plt.cm.Reds\n",
    "blueMap = plt.cm.Blues\n",
    "purpleMap = plt.cm.Purples\n",
    "\n",
    "grmap1 = greenMap(np.arange(greenMap.N))\n",
    "rdmap1 = redMap(np.arange(redMap.N))\n",
    "blmap1 = blueMap(np.arange(blueMap.N))\n",
    "prmap1 = purpleMap(np.arange(purpleMap.N))\n",
    "\n",
    "grmap1[:,-1] = np.linspace(0, 1, greenMap.N)**5\n",
    "rdmap1[:,-1] = np.linspace(0, 1, redMap.N)**5\n",
    "blmap1[:,-1] = np.linspace(0, 1, blueMap.N)**5\n",
    "prmap1[:,-1] = np.linspace(0, 1, purpleMap.N)**5\n",
    "\n",
    "grmap1[:100,-1] = 0\n",
    "rdmap1[:100,-1] = 0\n",
    "blmap1[:100,-1] = 0\n",
    "prmap1[:100,-1] = 0\n",
    "\n",
    "grmap = ListedColormap(grmap1)\n",
    "rdmap = ListedColormap(rdmap1)\n",
    "blmap = ListedColormap(blmap1)\n",
    "prmap = ListedColormap(prmap1)\n",
    "\n",
    "green_grid = z2_vals[:,0].reshape(100,100)\n",
    "#print(np.shape(green_grid))\n",
    "#plt.pcolormesh(green_grid, cmap=grmap)\n",
    "\n",
    "red_grid = z2_vals[:,1].reshape(100,100)\n",
    "#print(np.shape(red_grid))\n",
    "#plt.pcolormesh(red_grid, cmap=rdmap)\n",
    "\n",
    "blue_grid = z2_vals[:,2].reshape(100,100)\n",
    "#print(np.shape(blue_grid))\n",
    "#plt.pcolormesh(blue_grid, cmap=blmap)\n",
    "\n",
    "purple_grid = z2_vals[:,3].reshape(100,100)\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#fig = plt.figure(frameon=False)\n",
    "\n",
    "#z1 = plt.imshow(green_grid, cmap=grmap, origin='lower', interpolation = 'bilinear')\n",
    "#z2 = plt.imshow(red_grid, cmap=rdmap, origin='lower', interpolation = 'bilinear')\n",
    "#z3 = plt.imshow(blue_grid, cmap=blmap, origin='lower', interpolation = 'bilinear')\n",
    "#z4 = plt.imshow(purple_grid, cmap=prmap, origin='lower', interpolation = 'bilinear')\n",
    "#z3 = ax.scatter(gridz[:,0],gridz[:,1],c=blue, cmap=blmap)\n",
    "#z4 = ax.scatter(gridz[:,0],gridz[:,1],c=purple, cmap=prmap)\n",
    "\n",
    "#ax.scatter(gridz[:,0],gridz[:,1],c=sdevs, cmap='Greys')\n",
    "#z5 = plt.scatter(x_new[:,0],x_new[:,1],c=y,cmap=newcmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
